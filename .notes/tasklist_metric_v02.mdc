---
description: 
globs: 
alwaysApply: false
---
# GitHub 지표 수집 시스템 구현 태스크리스트 (Vite, Shadcn UI, Tailwind CSS, Drizzle ORM, Neon/PostgreSQL)

## Phase 1: 프로젝트 설정 및 기본 구조 (1주)

### Task 1.1: 데이터베이스 스키마 설계 (Drizzle ORM, PostgreSQL 적용)  
- **목표**: Drizzle ORM을 사용하여 SQLite에서 **PostgreSQL**로 전환된 데이터베이스 스키마를 설계하고 마이그레이션 준비  
- **상세 내용**:  
  - **스키마 정의 변경**: `sqliteTable`에서 **`pgTable`**로 변경하여 PostgreSQL에 맞는 테이블 스키마 정의  
    ```typescript
    // src/db/schema.ts 예시 (PostgreSQL)
    import { pgTable, serial, text, integer, timestamp } from 'drizzle-orm/pg-core';
    
    export const repositories = pgTable('repositories', {
      id: serial('id').primaryKey(),
      name: text('name').notNull(),
      fullName: text('full_name').notNull().unique(),
      cloneUrl: text('clone_url').notNull(),
      localPath: text('local_path'),
      lastSyncAt: timestamp('last_sync_at', { withTimezone: false }).defaultNow()
    });
    
    export const users = pgTable('users', {
      id: serial('id').primaryKey(),
      githubId: integer('github_id').unique(),
      login: text('login').notNull().unique(),
      name: text('name'),
      email: text('email'),
      avatarUrl: text('avatar_url')
    });
    
    export const commits = pgTable('commits', {
      id: text('id').primaryKey(),  // Git commit SHA
      repositoryId: integer('repository_id').notNull().references(() => repositories.id),
      authorId: integer('author_id').references(() => users.id),
      committerId: integer('committer_id').references(() => users.id),
      message: text('message'),
      committedAt: timestamp('committed_at', { withTimezone: false }).notNull(),
      additions: integer('additions'),
      deletions: integer('deletions')
    });
    // (pullRequests, prReviews 등 다른 테이블도 pgTable로 정의)
    ```  
  - **Drizzle 구성 업데이트**: 마이그레이션 도구 설정을 PostgreSQL용으로 변경  
    ```typescript
    // drizzle.config.ts (PostgreSQL 설정)
    import type { Config } from 'drizzle-kit';
    
    export default {
      schema: './src/db/schema.ts',
      out: './src/db/migrations',
      driver: 'pg',
      dbCredentials: {
        connectionString: process.env.DATABASE_URL!,  // Neon PostgreSQL 연결 문자열 (.env에 설정)
      },
    } satisfies Config;
    ```  
  - **DB 연결 초기화**: `better-sqlite3`에서 **node-postgres** (`pg` 패키지) 기반으로 변경하여 Neon 데이터베이스에 연결  
    ```typescript
    // src/db/index.ts
    import { Pool } from 'pg';
    import { drizzle } from 'drizzle-orm/node-postgres';
    import * as schema from './schema';
    
    // PostgreSQL 데이터베이스 연결 (Neon)
    const pool = new Pool({
      connectionString: process.env.DATABASE_URL,
    });
    export const db = drizzle(pool, { schema });
    ```  
  - **마이그레이션 실행**: Drizzle Kit으로 변경된 스키마를 기반으로 **PostgreSQL**에 마이그레이션 실행 (예: `pnpm drizzle:push`)하여 테이블 생성  
  - **환경 변수 설정**: `.env` 파일에 Neon **PostgreSQL 연결 정보** 추가 (`DATABASE_URL`) 및 기존 SQLite 경로 제거  
  - **데이터 정합성 확인**: 기존 SQLite 스키마와 새로운 PostgreSQL 스키마를 비교하여 누락된 인덱스나 제약 조건이 없는지 검토 (예: 자동 증가 시퀀스 등)  

### Task 1.2: 데이터 마이그레이션 (SQLite → PostgreSQL)  
- **목표**: 기존 SQLite에 저장된 데이터를 PostgreSQL(Neon)로 이전하여 연속성을 확보  
- **상세 내용**:  
  - **마이그레이션 스크립트 작성**: Node.js 스크립트를 만들어 SQLite DB에서 데이터를 읽어와 PostgreSQL에 삽입  
    - 예: `better-sqlite3`로 SQLite 파일(`./data/github-metrics.db`)에서 모든 테이블 레코드를 조회하고, `db.insert(...)`를 이용해 PostgreSQL에 동일한 데이터를 추가  
    - 사용자, 저장소, 커밋 등 **테이블별**로 데이터 이관 순서를 정하여 참조 관계 만족 (예: users → repositories → commits 순)  
  - **데이터 변환 처리**: SQLite와 PostgreSQL 간 데이터 타입 차이를 보정 (예: SQLite의 timestamp 숫자를 PostgreSQL의 날짜 형식으로 변환)  
  - **무결성 검증**: 마이그레이션 후 **레코드 수 비교** 및 중요 데이터 필드 샘플 검증으로 모든 데이터가 정상 이전되었는지 확인  
  - **백업**: 마이그레이션 과정에서 데이터 유실에 대비해 SQLite DB 백업 보관  

### Task 1.3: 저장소 관리 모듈 구현  
- **목표**: 대상 GitHub 저장소를 로컬에 클론/업데이트하고 경로를 관리하는 모듈 개발  
- **상세 내용**:  
  - **저장소 클론 및 업데이트**: `simple-git` 라이브러리를 활용하여 주어진 GitHub 저장소를 지정 경로에 **클론**, 이후 동기화 시 **fetch/pull**로 최신화  
  - **로컬 경로 관리**: 저장소 별 **로컬 디렉토리 경로**와 마지막 동기화 시간을 데이터베이스에 저장 (`repositories.localPath`, `lastSyncAt` 필드)  
  - **구현 예시**: 저장소가 존재하지 않으면 클론, 존재하면 최신 커밋까지 pull 하는 `RepositoryManager` 클래스 구현  
    ```typescript
    // src/services/repository-manager.ts
    import simpleGit, { SimpleGit } from 'simple-git';
    import { mkdir } from 'fs/promises';
    import { join } from 'path';
    import { db } from '../db';
    import { repositories } from '../db/schema';
    import { eq } from 'drizzle-orm';
    import { logger } from '../utils/logger';
    
    export class RepositoryManager {
      private basePath: string;
    
      constructor(basePath = './repos') {
        this.basePath = basePath;
        this.ensureBaseDirectory();
      }
    
      private async ensureBaseDirectory() {
        try {
          await mkdir(this.basePath, { recursive: true });
        } catch (error) {
          logger.error(`Failed to create base directory: ${error}`);
        }
      }
    
      async ensureRepository(repoInfo: typeof repositories.$inferSelect) {
        const repoPath = join(this.basePath, repoInfo.name);
        const git: SimpleGit = simpleGit();
    
        try {
          // 이미 클론되어 있는지 확인
          await git.checkIsRepo(join(repoPath, '.git'));
          // 이미 클론되어 있으면 업데이트
          logger.info(`Updating repository ${repoInfo.fullName}...`);
          const repo = git.cwd(repoPath);
          await repo.fetch('origin');
          await repo.pull();
          logger.info(`Repository ${repoInfo.fullName} updated`);
        } catch {
          // 저장소 최초 클론
          logger.info(`Cloning repository ${repoInfo.fullName}...`);
          await git.clone(repoInfo.cloneUrl, repoPath);
          logger.info(`Repository ${repoInfo.fullName} cloned`);
        }
    
        // DB에 로컬 경로와 마지막 동기화 시간 저장
        await db.update(repositories)
          .set({ localPath: repoPath, lastSyncAt: new Date() })
          .where(eq(repositories.id, repoInfo.id));
    
        return repoPath;
      }
    }
    ```  
  - **로깅**: 각 단계(success/failure)에 대해 `logger`를 통해 로그 남기기 (성공적인 클론, 업데이트 결과 등)  
  - **환경 설정**: 기본 클론 경로 (`./repos`)를 설정 파일이나 환경 변수로 뽑아내어 유연성 확보 (필요시 팀별로 다른 경로 설정 가능)  

## Phase 2: 데이터 수집 모듈 개발 (2주)

### Task 2.1: Git 기반 커밋 데이터 수집기 구현  
- **목표**: 로컬 Git 저장소를 대상으로 **커밋 데이터를 추출**하고 DB에 저장  
- **상세 내용**:  
  - **Git 로그 파싱**: `simple-git`을 이용하여 지정된 저장소 경로의 Git 커밋 로그를 읽어와 커밋 목록을 획득  
    - 옵션 설정으로 `--since` 파라미터를 사용해 **마지막 동기화 시점 이후**의 커밋만 수집 (증분 수집)  
    - `--numstat` 옵션을 사용하여 커밋별 **코드 변경량(추가/삭제)** 정보 함께 가져오기  
  - **중복 처리**: 각 커밋 SHA를 기본 키로 사용하여 **이미 수집된 커밋인지 확인**. DB에 존재하는 커밋은 건너뛰고 새로운 커밋만 처리  
  - **작성자 정보 저장**: 커밋 작성자의 이름, 이메일로 **사용자 식별**. 사용자 테이블에 해당 사용자가 없으면 새로 추가하고, 있으면 기존 사용자 ID 참조  
  - **DB 저장**: 커밋 정보를 `commits` 테이블에 삽입 (SHA, 작성자/커미터 ID, 메시지, 타임스탬프, 추가/삭제 줄 수 등)  
    ```typescript
    // src/services/git-collector.ts (일부 발췌)
    export class GitCommitCollector {
      async collectCommits(repoId: number, repoPath: string, since?: Date, branches?: string[]) {
        // ... (SimpleGit 초기화 및 브랜치 결정 로직)
        for (const branch of branches) {
          const logs = await git.log([...]);  // 해당 브랜치의 커밋 로그
          for (const commit of logs.all) {
            // 이미 DB에 있는 커밋은 건너뛰기
            const existingCommit = await db.select().from(commits)
              .where(eq(commits.id, commit.hash))
              .get();
            if (existingCommit) continue;
            
            // 작성자 정보 처리 (없으면 사용자 추가)
            const author = await this.getOrCreateUser(commit.author_name, commit.author_email);
            
            // 변경 통계 파싱
            const stats = { additions: 0, deletions: 0 };
            for (const numStat of commit.diff?.numstat || []) {
              stats.additions += parseInt(numStat.additions) || 0;
              stats.deletions += parseInt(numStat.deletions) || 0;
            }
            
            // 커밋 정보를 DB에 저장
            await db.insert(commits).values({
              id: commit.hash,
              repositoryId: repoId,
              authorId: author.id,
              message: commit.message,
              committedAt: new Date(commit.date),
              additions: stats.additions,
              deletions: stats.deletions
            });
          }
        }
      }
    }
    ```  
  - **오류 처리 및 로깅**: 수집 중 발생하는 오류를 로그로 기록하고 다음 커밋으로 진행 (한 커밋 실패가 전체 중단되지 않도록)  
  - **성과 지표 필드**: 커밋에 대한 라인 추가/삭제 정보(`additions`, `deletions`)를 저장함으로써 향후 **코드 변경량(LOC)** 지표 계산에 활용  

### Task 2.2: GitHub API 연동 모듈 구현  
- **목표**: **GitHub API (GraphQL 또는 REST)**를 사용하여 Pull Request(PR) 및 리뷰 데이터를 수집하고 데이터베이스에 저장  
- **상세 내용**:  
  - **Octokit 설정**: GitHub의 REST/GraphQL API 호출을 위해 Octokit 라이브러리 초기화 및 **인증 토큰** 설정 (.env의 `GITHUB_TOKEN` 사용)  
  - **PR 데이터 수집**: 대상 저장소의 **Pull Request 목록**을 불러와 각 PR의 주요 정보 저장  
    - 예: PR 번호, 제목, 작성자, 생성일시, 병합일시(또는 닫힌 일시), 상태(open/merged/closed), 변경된 코드 라인 수 등을 `pullRequests` 테이블에 저장  
    - **그래프QL 활용**: 필요한 경우 GraphQL로 PR과 연관된 리뷰, 커밋 수를 한 번에 조회하여 API 호출 횟수 최적화  
  - **리뷰 데이터 수집**: 각 PR에 달린 **코드 리뷰(review)** 정보 수집  
    - PR에 대한 리뷰어, 리뷰 제출 시간, 리뷰 상태(승인/요청 변경 등)를 가져와 `prReviews` 테이블에 저장  
    - 리뷰 응답 시간 계산을 위해 **PR 생성 시간과 첫 승인 리뷰 시간** 등을 확보  
  - **사용자 데이터 보강**: PR 작성자나 리뷰어 중 **시스템에 없는 사용자는 사용자 테이블에 추가** (ex: 외부 협업자가 PR에 참여한 경우)  
  - **데이터 관계**: PR과 커밋/리뷰 데이터 연계를 위해 foreign key 관계 유지 (commits → repository, pullRequests → repository, prReviews → pullRequest 등)  
  - **예외 처리**: API rate limit이나 네트워크 오류 발생 시 지수적 backoff 재시도, 실패한 항목 로그 기록  

### Task 2.3: 증분 동기화 및 통합 수집 관리  
- **목표**: **증분 데이터 수집** 및 여러 종류의 데이터를 일괄 동기화하는 관리자 모듈 구현  
- **상세 내용**:  
  - **Sync Manager 설계**: 커밋 수집기(Git)와 PR/리뷰 수집기(GitHub API)를 **통합**하여 단일 진입점에서 저장소 데이터를 동기화하는 `SyncManager` 클래스 구현  
  - **최신 동기화 시점 관리**: `repositories.lastSyncAt` 값을 활용하여 각 저장소별 **마지막 동기화 이후** 추가된 커밋과 PR만 가져오도록 수집기 호출  
    - 커밋 수집: `GitCommitCollector.collectCommits(repoId, path, since=lastSyncAt)`  
    - PR 수집: GitHub API 호출 시 `updated_at > lastSyncAt` 조건 또는 GraphQL `since` 필터 활용  
  - **동기화 단계**: 저장소 단위로 (1) RepositoryManager 통해 **최신 코드 받기** → (2) GitCommitCollector로 **커밋 수집** → (3) GitHub API로 **PR 및 리뷰 수집** 순으로 실행  
  - **일괄 처리**: 여러 저장소를 순차 또는 병렬로 처리하여 전체 프로젝트의 데이터를 업데이트하고, 프로세스 **진행 상황을 로깅**  
  - **에러 격리**: 특정 저장소 동기화 중 에러 발생 시 해당 저장소만 스킵하고 다음 대상으로 진행, 전반적인 동기화 작업은 지속  
  - **마지막 동기화 시간 갱신**: 모든 수집이 끝나면 `repositories.lastSyncAt`를 현재 시각으로 업데이트하여 다음 증분 수집에 활용  

### Task 2.4: JIRA 이슈 데이터 연동 (팀별 활동량 보조 지표)  
- **목표**: 소프트웨어 개발 **프로세스 지표** 강화를 위해 JIRA와 연동, 팀별 **이슈 처리량** 등 추가 수집  
- **상세 내용**:  
  - **JIRA API 설정**: JIRA 클라우드의 REST API 사용을 위한 **Base URL, 인증 토큰** 등을 설정 (config 파일 또는 환경 변수에 저장)  
  - **이슈 쿼리**: JIRA의 Search API를 활용하여 **지정된 기간** 동안 팀 관련 프로젝트의 **완료된 이슈** 목록을 조회 (예: JQL로 `status = Done AND updated >= startDate`)  
  - **데이터 파싱**: 이슈 키, 제목, 담당자, 완료 일시 등의 정보를 파싱하여 내부 지표 계산에 활용  
    - 팀별 이슈 처리량 산정을 위해 **이슈 완료 건수** 및 **평균 처리 시간** 등을 추출  
    - 담당자와 우리 시스템 사용자 매핑이 가능하다면, 각 사용자의 이슈 처리 건수를 집계  
  - **데이터 저장/활용**: 간단한 통계치(예: 기간 내 완료 이슈 개수)를 바로 계산하여 메모리에 보관하거나, 필요시 `issues`라는 별도 테이블에 이슈 정보를 저장  
  - **연계 활용**: 수집된 JIRA 데이터를 **팀 지표 계산 모듈**에서 활용하여 개발 활동 지표(GitHub)와 프로젝트 관리 지표(JIRA)를 결합한 **팀 단위 종합 지표** 산출  
  - **오류 및 한계**: JIRA API 연동이 실패할 경우 로그를 남기되 핵심 기능에는 영향 없도록 하며, JIRA 데이터는 없으면 해당 지표를 "N/A" 또는 0 처리  

## Phase 3: 지표 계산 및 분석 엔진 (2주)

### Task 3.1: 핵심 지표 계산 모듈 구현 (개인별, 프로젝트별, 팀별 메트릭)  
- **목표**: 수집된 데이터를 바탕으로 **개발자별, 프로젝트별, 팀별 핵심 지표**를 계산하고 제공  
- **상세 내용**:  
  - **개인별 지표**: 특정 개발자의 기간별 **커밋 수**, **PR 수**, **코드 리뷰 참여 횟수** 등을 계산  
    - 예: 최근 90일 간 커밋 수, 총 코드 추가/삭제량, 작성 PR 개수, 리뷰 남긴 PR 개수, **활동일 수**(커밋 또는 PR이 발생한 일자 수)  
    - 개인별 **평균 PR 리드 타임**(PR 생성부터 병합까지 소요 시간) 등 산출하여 개발자 생산성 파악  
  - **프로젝트 지표**: 저장소(프로젝트) 단위 **변경 빈도**, **PR 리드 타임**, **PR 병합 비율** 등을 계산  
    - 예: 프로젝트별로 주간 평균 배포 빈도, PR의 평균 사이클 타임(오픈→머지 소요시간), 머지된 PR 비율 등을 도출  
    - **DORA 메트릭**(Deployment Frequency, Lead Time for Changes, Change Failure Rate, MTTR) 중 관련 지표 계산 가능 시 포함  
  - **팀별 지표**: 팀 구성원 전체의 **활동을 집계**하여 팀 수준 생산성을 측정  
    - 팀원들의 커밋 수와 PR 수를 합산하고, 코드 리뷰 횟수를 합산  
    - **팀별 총 변경 LOC** (모든 팀원의 코드 추가/삭제 합계), **팀별 완료 이슈 수**(JIRA 연동 시), **평균 PR 리드 타임**(팀 내 PR 평균) 등을 계산  
    - 여러 팀의 결과를 비교해 **팀 성과 비교 지표** 생성 (예: 팀 A vs 팀 B의 분기별 PR 수 혹은 배포 빈도 비교)  
  - **지표 계산 예시 구현**: Metrics 계산기 클래스(`MetricsCalculator`)에 각 범주별 계산 메서드 구현  
    ```typescript
    // src/services/metrics-calculator.ts (팀 지표 계산 예시)
    import { db } from '../db';
    import { commits, pullRequests } from '../db/schema';
    import { and, gte, lte, sql, inArray } from 'drizzle-orm';
    import teamConfig from '../config/teams.json';  // 팀 구성원 정보 (예: 팀별 사용자 목록)
    
    export class MetricsCalculator {
      async calculateTeamMetrics(teamName: string, startDate: Date, endDate: Date) {
        const memberIds = teamConfig[teamName]?.members || [];  // 팀에 속한 사용자 ID 목록
        if (memberIds.length === 0) return null;
        // 팀 전체 커밋 수 계산
        const commitStats = await db.select({
            commitCount: sql`COUNT(*)`,
            totalAdditions: sql`SUM(${commits.additions})`,
            totalDeletions: sql`SUM(${commits.deletions})`
          })
          .from(commits)
          .where(and(
            inArray(commits.authorId, memberIds),
            gte(commits.committedAt, startDate),
            lte(commits.committedAt, endDate)
          ))
          .get();
        // 팀 전체 PR 수 및 병합율 계산
        const prStats = await db.select({
            prCount: sql`COUNT(*)`,
            mergedCount: sql`SUM(CASE WHEN ${pullRequests.state} = 'MERGED' THEN 1 ELSE 0 END)`,
            avgLeadTime: sql`AVG(DATE_PART('day', ${pullRequests.mergedAt} - ${pullRequests.createdAt}))`
          })
          .from(pullRequests)
          .where(and(
            inArray(pullRequests.authorId, memberIds),
            gte(pullRequests.createdAt, startDate),
            lte(pullRequests.createdAt, endDate)
          ))
          .get();
        // 필요시 추가 쿼리: 코드 리뷰 수, 완료된 JIRA 이슈 수 등
        return {
          commitCount: commitStats.commitCount,
          totalChanges: commitStats.totalAdditions + commitStats.totalDeletions,
          prCount: prStats.prCount,
          mergeRate: prStats.prCount ? (prStats.mergedCount / prStats.prCount) : 0,
          avgPrLeadTimeDays: prStats.avgLeadTime
        };
      }
    }
    ```  
    *(위 예시는 팀 멤버 ID 목록을 활용하여 해당 팀의 커밋/PR 통계를 집계하는 방식이다.)*  
  - **캐싱 및 최적화**: 빈번히 조회되는 지표는 DB의 캐시 테이블(`metricsCache`) 등에 저장하여 **24시간 등 일정 기간 캐시**하고, 재계산 부담을 줄임  
  - **검증 및 해석**: 계산된 지표의 정상 범위 검증 및 **의미 해석을 위한 주석** 또는 문서화 (지표의 한계와 해석 방법 명시)  

### Task 3.2: 멀티스레드 데이터 처리 관리자 구현  
- **목표**: **Node.js 워커 스레드**를 활용하여 데이터 수집 및 지표 계산 작업을 병렬 처리하고 성능 향상  
- **상세 내용**:  
  - **Worker Threads 도입**: 대용량 저장소 동시 처리 등 시간이 많이 걸리는 작업들을 백그라운드 스레드에서 실행하기 위해 `worker_threads` 모듈 활용  
  - **작업 분배 로직**: 처리해야 할 저장소 목록이나 작업 목록을 받아 **작업 큐**로 분할하고, 여러 워커에 균등 배분  
    - 예: 전체 저장소 리스트를 워커 수만큼 청크로 나누어 각 워커가 병렬로 `SyncManager.syncRepository` 등을 호출  
  - **워커 관리**: `WorkerManager` 클래스를 구현하여 **최대 워커 수**를 제한하고, 워커 생성/종료를 일괄 관리  
  - **결과 수집 및 재시도**: 각 워커가 완료되면 결과(성공/실패)를 취합하여 리턴. 실패한 작업에 대해서는 로그를 남기고 필요시 재시도 전략 수립  
  - **구현 예시**: 
    ```typescript
    // src/services/worker-manager.ts (병렬 작업 처리 예시)
    import { Worker } from 'worker_threads';
    import { logger } from '../utils/logger';
    import path from 'path';
    
    export class WorkerManager {
      constructor(private maxWorkers = 4) {}
    
      async runTasksInParallel(tasks: any[]) {
        // 작업을 워커 수만큼 청크로 분할
        const chunkSize = Math.ceil(tasks.length / this.maxWorkers);
        const chunks = [];
        for (let i = 0; i < tasks.length; i += chunkSize) {
          chunks.push(tasks.slice(i, i + chunkSize));
        }
        // 워커별 작업 할당 및 실행
        const results = await Promise.all(chunks.map(chunk => {
          return new Promise((resolve) => {
            const worker = new Worker(path.resolve(__dirname, '../workers/sync-worker.js'), {
              workerData: { tasks: chunk }
            });
            worker.on('message', resolve);
            worker.on('error', (err) => {
              logger.error(`Worker error: ${err}`);
              // 청크 내 모든 작업을 실패로 표시하여 반환
              resolve(chunk.map(task => ({ success: false, error: err })));
            });
          });
        }));
        return results.flat();
      }
    }
    ```  
  - **메모리 공유**: 필요한 경우 메모리 공유용 `SharedArrayBuffer`나 메시지 통신을 활용하여 워커 간 진행 상황을 모니터링  
  - **적용 범위**: 커밋/PR 수집 작업, 지표 대량 계산 등에 WorkerManager 적용하여 **응답 지연을 최소화**하고, 프론트엔드 요청에 대한 신속한 응답 보장  

## Phase 4: 프론트엔드 개발 (3주)

### Task 4.1: 대시보드 UI 레이아웃 및 컴포넌트 개발  
- **목표**: shadcn/UI 라이브러리와 Tailwind CSS를 활용하여 **직관적인 대시보드 UI** 구현  
- **상세 내용**:  
  - **레이아웃 구성**: 전체 애플리케이션의 기본 레이아웃과 **네비게이션 바**는 이미 구성 완료. 기존 코드를 사용함. 
  - **탭 구조**: 주요 지표 조회 화면들을 사이드바를 클릭하면 오른쪽의 screen에 표시하여 **전환** 가능하도록 설계  
  - **재사용 컴포넌트**: 카드(Card), 표(Table), 버튼, 입력 등 UI 컴포넌트를 shadcn UI 기반으로 개발하고, 다양한 지표 타입을 표시할 수 있도록 **컴포넌트화**. 이미 MetricCard라는 컴포넌트 1종을 만들었으니 참고
  - **필터/검색 UI**: 기간 선택(DateRangePicker), 팀/프로젝트 필터 드롭다운 등 이미 screen의 header 영역에 구현한 **데이터 필터링** 기능을 검토/추가 구현. 
  - **대시보드의 사이드바 필수 메뉴**:  
    - 개요(Overview) 대시보드 – 전체 시스템 요약 지표 (총 커밋 수, 전체 PR 수 등 주요 통계)  
    - 개발자 지표 뷰 – 개인별 활동 지표 상세 (선택된 개발자의 커밋/PR 추이 등)  
    - 프로젝트 지표 뷰 – 저장소별 성과 지표 (프로젝트 건강도, 변경 빈도 등)  
    - **팀 지표 뷰** – 팀 단위 종합 지표 (팀별 총 커밋, PR, DORA 지표 등)  
    - 비교 분석 뷰 – 개발자/프로젝트/팀 지표를 **비교 시각화** (예: 두 팀의 메트릭 비교)  
  - **UI 예시**: 현재 구성한 스크린 중심으로 위 화면들을 전환 구현 (shadcn Tabs 사용) 및 각 화면에 대응되는 컴포넌트 배치  
  - **반응형 디자인**: 데스크톱뿐 아니라 태블릿/모바일 화면에서도 주요 지표를 확인할 수 있도록 Tailwind 그리드/플렉스를 활용한 반응형 디자인 적용  

### Task 4.2: 데이터 시각화 컴포넌트 구현  
- **목표**: 수집된 지표 데이터를 **차트/그래프** 형태로 시각화하여 한눈에 이해할 수 있도록 함  
- **상세 내용**:  
  - **시계열 차트**: 시간 경과에 따른 추이를 보여주는 **라인 차트/영역 차트** 구현 (예: 날짜별 커밋 수, 주별 PR 생성 추이)  
  - **막대 그래프**: 비교 대상별 절대량을 보여주는 차트 (예: **개발자별 커밋 수**, **프로젝트별 배포 빈도** 등)  
    - 팀별 성과 비교를 위해 **팀별 PR 개수, 코드 변경량** 등을 표시하는 막대 그래프 추가  
  - **레이더 차트**: 여러 지표 차원을 한꺼번에 비교 (예: **DORA 메트릭** – 배포 빈도, 변경 리드타임, 변경 실패율, 복구 시간 등을 한눈에 비교)  
    - 프로젝트 A vs 프로젝트 B 또는 팀 A vs 팀 B의 상대적 지표 수준을 비교하는 용도로 활용  
  - **히트맵**: 시간대/요일별 활동 패턴 시각화 (예: GitHub contribution graph처럼 **커밋 빈도 히트맵**)  
  - **차트 구현**: Recharts 등의 차트 라이브러리 활용하여 React 컴포넌트 형태로 구현하고, 필요한 prop (데이터, 색상 등)을 받아 재사용 가능하도록 설계  
  - **샘플 컴포넌트**:  
    - `CommitActivityChart`: 특정 기간 동안 커밋 수를 영역차트로 표시  
    - `TeamComparisonBarChart`: 여러 팀의 PR 수나 커밋 수를 막대 차트로 비교 표시  
  - **상태 표시**: 데이터 로딩 중/실패 시 사용자에게 로딩 스피너나 에러 메시지 표시 등 UI 피드백 처리  

### Task 4.3: API 연동 및 상태 관리 구현  
- **목표**: 프론트엔드에서 백엔드 API를 호출하여 **실시간 데이터**를 가져오고, 전역 상태로 관리  
- **상세 내용**:  
  - **API 클라이언트 구성**: Axios 등을 이용하여 `/api` 하위 엔드포인트와 통신하는 공통 API 모듈 작성 (`src/api/client.ts` 등)  
    - 예: `getRepositories()`, `getMetricsByUser(userId)`, `getMetricsByTeam(teamName)` 등의 함수 구현  
    - **팀 지표 API 연동**: 팀별 메트릭을 가져오는 함수 (`getTeamMetrics(teamName)`) 추가하여 백엔드 새로운 팀 지표 엔드포인트와 연동  
  - **상태 관리**: Zustand 사용. 서버 상태를 캐싱 및 관리  
    - 쿼리 키를 개발자/프로젝트/팀별로 구분하고, 호출 결과를 캐시하여 탭 전환 시 재사용  
    - 동기화 트리거 등의 mutation은 로딩/성공 상태 관리하여 UI에 반영 (예: “동기화 중...” 표시)  
  - **에러 처리**: API 호출 실패 시 공통 처리 (토스트 알림 또는 해당 컴포넌트 영역에 에러 표시) 및 재시도 옵션 제공  
  - **데이터 필터링 연동**: UI의 날짜 범위, 팀/프로젝트 선택이 변경될 때마다 관련 API를 재호출하도록 훅(Hook) 구성  
  - **예시**: 
    ```typescript
    // src/api/client.ts 예시 (일부)
    import axios from 'axios';
    const apiClient = axios.create({ baseURL: '/api' });
    
    export const fetchTeamMetrics = async (teamName: string, from: Date, to: Date) => {
      const { data } = await apiClient.get(`/metrics/team/${teamName}`, {
        params: { from: from.toISOString(), to: to.toISOString() }
      });
      return data;
    };
    ```
    *(팀 이름과 기간을 지정하여 팀별 메트릭을 가져오는 API 호출 예시)*  
  - **실시간 갱신**: 주요 대시보드 화면에서 **주기적 갱신**이 필요한 데이터는 `setInterval` 또는 WebSocket 등을 통해 일정 간격마다 업데이트 (예: 실시간에 가까운 데이터 표시가 필요할 경우)  

### Task 4.4: 설정 및 관리 페이지 구현  
- **목표**: 사용자나 관리자용 **시스템 설정 및 데이터 관리 UI** 제공  
- **상세 내용**:  
  - **저장소 관리 UI**: 시스템에 등록된 프로젝트 저장소 목록을 보고, 새로운 저장소 추가 또는 기존 저장소 제거를 수행하는 인터페이스 구현  
    - 새 저장소 추가 시 GitHub URL 또는 정보 입력 -> 백엔드 API 호출로 저장소 정보 등록 및 초기 동기화  
    - 저장소별 활성/비활성 토글, 마지막 동기화 일시 표시  
  - **팀 정보 제공**: (팀별 메트릭 기능에 맞춰) 각 팀의 구성원 정보를 확인할 수 있는 화면 제공  
    - 팀 구성은 config 파일 기반이므로 **읽기 전용**으로 표시하거나, 필요시 별도 관리 도구 안내 (예: JSON 파일 편집)  
    - *추가 기능(선택사항)*: 간단한 팀 정보 편집 UI를 제공하고 편집 내용을 서버에 전송하여 config를 업데이트하는 기능 (프로토타입 단계에서는 파일 직접 수정으로 대체 가능)  
  - **시스템 설정**: API 토큰(GitHub, JIRA 등) 설정 상태, 데이터베이스 상태 등 주요 설정 값을 확인하는 화면  
  - **사용자 가이드**: 화면 내에 각 설정에 대한 설명과 주의사항을 표시하여 사용자 이해를 도움 (예: "새 저장소 추가 시, 초기 동기화에 몇 분 정도 소요될 수 있습니다.")  
  - **접근 제어**: 설정/관리 페이지는 관리자만 접근하도록 라우팅 가드 적용 (로그인 기능이 있다면 관리자 권한 체크)  


### Task 4.5: 트렌드 분석 및 예측 모듈 구현

- **목표**: 시간에 따른 메트릭 데이터 추세를 분석하고 미래 값을 예측하여 개발팀에게 통찰력 있는 정보를 제공하는 모듈을 구현
- **상세 내용**:
  - **시계열 데이터 처리 유틸리티** 구현
    - 수집된 메트릭 데이터를 시계열 형식으로 변환
    - 시간 단위(일/주/월/분기) 별 데이터 집계 기능
    - 이동 평균, 표준편차 등 기본 통계 계산 기능
  - **트렌드 감지 알고리즘 구현**
    - 메트릭 데이터의 상승/하락 추세 감지
    - 이상치 탐지 및 특이 패턴 식별
    - 시즌성 분석 (주간/월간 패턴 등)
  - **기본 예측 모델 구현**
    - 선형 회귀 기반 기본 예측 모델
    - 지수 평활법을 활용한 단기 예측
    - 신뢰 구간 계산 및 예측 불확실성 정량화
  - **트렌드 시각화 컴포넌트 구현**
    - 추세선 및 예측선 표시 기능
    - 신뢰 구간 시각화
    - 이상치 및 주요 변화 포인트 강조 표시
  - **예측 모델 평가 및 개선 메커니즘 구현**
    - 예측 정확도 측정 지표 구현
    - 모델 재학습 및 파라미터 최적화 기능
    - A/B 테스트 프레임워크 구축

- **구현 요구사항**
  - 대규모 시계열 데이터 처리를 위한 효율적인 알고리즘 사용
  - 멀티스레드 데이터 처리 관리자와 통합
  - 사용자 정의 예측 모델 플러그인 가능한 아키텍처 설계
  - 현대적인 UI/UX로 트렌드 및 예측 결과 표현

- **산출물** 
  - 시계열 데이터 처리 클래스
  - 트렌드 분석 및 예측 알고리즘
  - 예측 결과 시각화 컴포넌트
  - 예측 모델 평가 및 튜닝 유틸리티
  - 사용 설명서 및 API 문서

- **테스트 기준**
  - 다양한 메트릭에 대한 트렌드 감지 정확도 검증
  - 예측 모델의 MAPE(Mean Absolute Percentage Error) 20% 이하
  - 대규모 데이터셋(1년 이상)에 대한 처리 성능 검증
  - 다양한 시나리오에 대한 사용자 경험 테스트

## Phase 5: 백엔드 API 및 시스템 통합 (1-2주)

### Task 5.1: Express API 서버 및 라우트 구현  
- **목표**: 백엔드 Express 서버를 구축하고 필요한 **REST API 엔드포인트** 구현  
- **상세 내용**:  
  - **서버 기본 설정**: Express 앱 초기화 및 미들웨어 설정 (CORS 허용, Helmet 보안 헤더 적용, `express.json()`으로 JSON 바디 파싱)  
  - **라우트 구성**: 주요 도메인별로 라우터 모듈 분리 및 등록  
    - **저장소 라우트** (`/api/repositories`): 프로젝트 저장소 목록 조회, 추가, 삭제 API  
    - **메트릭스 라우트** (`/api/metrics`): 지표 데이터 제공 API  
      - 예: GET `/api/metrics/developer/:id` (개인별 지표), GET `/api/metrics/project/:id` (프로젝트 지표)  
      - **신규**: GET `/api/metrics/team/:teamName` (팀별 지표) 엔드포인트 추가 – 요청된 팀 이름에 해당하는 팀 구성원들의 집계 지표를 계산하여 반환  
    - **동기화 라우트** (`/api/sync`): 데이터 수집 트리거 API (예: POST로 특정 저장소 동기화 실행)  
    - *(필요시)* **팀 정보 라우트** (`/api/teams`): 팀 목록 및 팀 구성원 정보를 제공하는 API (config 파일의 내용을 반환하여 프론트엔드가 팀 선택에 활용)  
  - **컨트롤러 구현**: 각 라우트별 동작 구현  
    - 저장소 컨트롤러: DB에서 저장소 목록 조회 또는 신규 저장소 추가 시 RepositoryManager와 SyncManager 호출  
    - 메트릭 컨트롤러: MetricsCalculator를 사용하여 요청된 범위의 지표 계산 결과 반환 (개인/프로젝트/팀 유형에 따라 분기)  
    - 동기화 컨트롤러: SyncManager로 전체 또는 특정 저장소 동기화 작업 실행 (비동기로 처리하고 즉시 응답 또는 작업 큐에 추가)  
  - **팀 메트릭 처리**: `/metrics/team/:teamName` 요청을 받으면 **팀 구성원 식별**을 위해 config의 팀 정보를 로드하여 MetricsCalculator에 전달, 결과를 응답  
  - **공통 미들웨어**: 로깅(mid) – 모든 요청에 대해 요청 경로와 메서드 로그, 에러 핸들러 – 예외 발생 시 표준 에러 응답(JSON) 반환  
  - **예시**: 
    ```typescript
    // src/server/index.ts (일부)
    import express from 'express';
    import { repositoryRoutes } from './routes/repository';
    import { metricsRoutes } from './routes/metrics';
    import { syncRoutes } from './routes/sync';
    ...
    const app = express();
    app.use(express.json());
    app.use('/api/repositories', repositoryRoutes);
    app.use('/api/metrics', metricsRoutes);
    app.use('/api/sync', syncRoutes);
    app.use('/api/teams', teamsRoutes);  // 팀 정보 라우트 추가
    ```  
  - **정적 파일 서빙**: 빌드된 프론트엔드 (dist 폴더)를 Express가 서빙하여 단일 프로젝트로 운영 (프론트엔드 라우팅 대비 모든 기타 요청을 `index.html`로 처리)  
  - **보안**: (선택) JWT 등을 활용한 **인증/인가 미들웨어** 삽입하여 민감 기능 보호, 혹은 IP 제한 등의 기본 보안 적용  

### Task 5.2: 백그라운드 작업 스케줄러 구현  
- **목표**: **주기적인 데이터 수집 및 지표 갱신**이 자동으로 이뤄지도록 백엔드 스케줄러 구성  
- **상세 내용**:  
  - **스케줄러 설정**: `node-cron` 라이브러리를 사용하여 정해진 일정에 작업 수행  
    - 예: 매일 새벽 1시에 모든 저장소 **동기화 작업** 실행 → 최신 데이터로 갱신  
    - 매주 일요일 새벽 2시에 **지표 캐시** 초기화 또는 장기 미사용 데이터 정리  
  - **동기화 작업**: 정기 실행 시 `SyncManager`를 사용하여 **모든 저장소에 대한 데이터 수집** 수행 (Task 2.3에서 구현한 흐름 호출)  
    - 실행 전후로 로그 남겨서 자동 작업 결과 추적 (성공/실패한 저장소 수 등)  
  - **JIRA 연동 작업**: (연동하는 경우) 매일 일정 시간에 JIRA 이슈 데이터 갱신 작업도 추가  
    - 예: 매일 새벽 3시에 JIRA API 호출하여 지난 하루 동안 완료된 이슈 수 집계 → DB 또는 캐시에 업데이트  
  - **리소스 관리**: 스케줄된 작업이 겹치지 않도록 **mutex** 또는 플래그를 두어 이전 작업이 끝나기 전에 중복 실행되지 않게 보호  
  - **관리 UI 연동**: (선택) 관리 페이지에서 현재 설정된 크론 스케줄 확인 및 수동 실행 트리거 버튼 제공 (예: “지금 동기화 실행” 버튼은 `/api/sync` 엔드포인트를 호출)  
  - **확장성 고려**: 향후 작업 종류가 늘어날 경우를 대비해 스케줄러를 **서비스 클래스**로 추상화하고 여러 작업 일정을 체계적으로 관리 (예: config에 스케줄 정의)  

## Phase 6: 테스트 및 배포 (1주)

### Task 6.1: 테스트 작성 및 실행  
- **목표**: 주요 기능에 대한 테스트를 작성하여 코드 품질을 보장하고 회귀 방지  
- **상세 내용**:  
  - **유닛 테스트**: Vitest를 사용하여 **데이터 수집기, 지표 계산 모듈** 등의 로직을 단위 테스트  
    - 예: MetricsCalculator의 개발자 지표 계산 함수에 여러 시나리오의 입력 데이터를 주고 기대값 검증 (커밋 수 합계, PR 병합율 계산 등)  
    - 팀 지표 계산 함수에 가상의 팀 구성원 및 데이터셋을 주고 정확한 합산이 이루어지는지 테스트  
    - GitCommitCollector의 커밋 필터링 로직 테스트 (이미 처리된 커밋은 건너뛰는지 등)  
  - **통합 테스트**: Express API 엔드포인트에 대해 슈퍼테스트(supertest) 등으로 통합 테스트 수행  
    - 예: `/api/metrics/developer/1?from=X&to=Y` 호출 시 올바른 JSON 응답과 상태 코드를 반환하는지 확인  
    - 잘못된 팀 이름으로 `/api/metrics/team/UnknownTeam` 호출 시 404 또는 에러 메시지 응답 확인  
  - **프론트엔드 테스트**: React 컴포넌트와 상태 관리에 대해 기본적인 렌더링 테스트 및 상호작용 테스트 작성  
    - 대시보드 탭 전환 시 올바른 컴포넌트 렌더링 여부, API 호출 훅이 정상 호출되는지 등을 JSDom 환경에서 검증  
  - **테스트 데이터베이스**: 테스트 실행 시에는 **별도의 테스트용 PostgreSQL 데이터베이스** 또는 SQLite 메모리 DB를 사용하여 실제 데이터 훼손 방지  
  - **지속적 테스트**: PR 생성 시 CI에서 테스트 자동 실행되도록 구성하여 **품질 게이트** 마련  

### Task 6.2: 배포 준비 및 문서화  
- **목표**: 서비스 배포를 위한 환경 구성 완료 및 사용자/운영 문서 작성  
- **상세 내용**:  
  - **환경 구성**: 프로덕션 환경에서 Neon PostgreSQL 데이터베이스 연결을 위해 **환경 변수 설정** (DATABASE_URL) 확인 및 README에 예시 추가  
  - **빌드 & 배포**: 프론트엔드(React) 프로덕션 빌드(output `dist/`) 및 백엔드(Node) 서버를 함께 실행할 수 있도록 **프로세스 매니저** 또는 컨테이너(Docker) 설정  
    - Dockerfile 작성 시 multi-stage로 프론트엔드 빌드 -> 정적 파일 복사 -> 백엔드 실행 환경 구성  
    - 또는 Vercel/Netlify 등의 플랫폼에 맞게 환경 구성 스크립트 작성  
  - **마이그레이션 적용**: 배포 전 반드시 Drizzle **마이그레이션 실행** (`pnpm drizzle:push` 등)하여 스키마 최신화 및 초기 데이터 반영  
  - **모니터링 설정**: 운영 환경에서 로그 모니터링을 위한 설정 (예: Neon DB 모니터링 대시보드 활성화, Sentry 등 오류 수집 도구 연결)  
  - **문서화**: 사용자를 위한 **README.md** 업데이트  
    - 프로젝트 소개, 주요 기능 설명  
    - 설치 및 실행 방법 (Neon 계정 생성, `.env` 설정, `pnpm dev` 등)  
    - 팀별 지표 기능 안내 (팀 구성 파일 경로와 포맷 설명, 예: `config/teams.json` 편집 방법)  
    - 지표 해석 가이드 (각 지표가 의미하는 바와 주의사항)  
  - **기술 문서**: 개발자를 위한 추가 문서화 (아키텍처 다이어그램, 테이블 스키마 정의서, 주요 모듈 설명 등) 작성하여 저장소에 포함  